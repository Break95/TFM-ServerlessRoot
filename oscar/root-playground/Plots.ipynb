{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35de087a",
   "metadata": {},
   "source": [
    "# Experiment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad1154",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf931a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500158cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import statistics\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8aa30",
   "metadata": {},
   "source": [
    "### Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588cac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mapper_times(csvs):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    times = {}\n",
    "    for item in csvs:\n",
    "        tmp = csvs[item]\n",
    "        tmp = tmp[tmp['function'] ==  'mapper']\n",
    "\n",
    "        tmp_time = []\n",
    "        name = f'size_{item.split(\"_\")[0]}'\n",
    "\n",
    "        times[name] = [[], []]\n",
    "        for elem in pd.unique(tmp['id']):\n",
    "            tmp2 = tmp[tmp['id'] == elem]\n",
    "            mapper_time = float(tmp2['time'].iloc[[-1]].values[0]) - float(tmp2['time'].iloc[[0]].values[0]) \n",
    "            tmp_time.append(mapper_time)\n",
    "            times[name][0].append(tmp2['time'].iloc[[-1]].values[0] - tmp2['time'].iloc[[0]].values[0]) \n",
    "            times[name][1].append(tmp2['node'].iloc[[-1]].values[0])\n",
    "            #times[name][0].sort()\n",
    "\n",
    "        print(f'Job: {name}. Average Time: {sum(tmp_time)/len(tmp_time)} - Median: {statistics.median(tmp_time)}')\n",
    "\n",
    "\n",
    "    for k in times:\n",
    "        bp = go.Figure()\n",
    "        bp.add_trace(go.Box(y=times[k][0], \n",
    "                            name=f'Job {k}', \n",
    "                            boxpoints='all', \n",
    "                            text=times[k][1]))\n",
    "\n",
    "        bp.show()\n",
    "       \n",
    "    \n",
    "def eficiency(csvs):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    jobs = ['1','3','6','12','24','48','96']\n",
    "    times = []\n",
    "    \n",
    "    for item in csvs.keys(): \n",
    "        tmp = csvs[item]\n",
    "        tmp = tmp[tmp['function'] == 'mapper']\n",
    "        max_time = 0\n",
    "        \n",
    "        # Para cada mapper de este trabajo buscar el tiempo maximo\n",
    "        for elem in pd.unique(tmp['id']):\n",
    "            tmp2 = tmp[tmp['id'] == elem]\n",
    "            if max_time < tmp2['time'].iloc[[-1]].values[0]:\n",
    "                max_time = tmp2['time'].iloc[[-1]].values[0]\n",
    "        \n",
    "        times.append(max_time)\n",
    "\n",
    "    efi_ts = list(map(lambda x: times[0] / x , times))\n",
    "    efi_jobs = [float(i) for i in jobs]\n",
    "\n",
    "    # Creacion del grafico\n",
    "    fig = make_subplots(rows=1, cols=2,\n",
    "                       subplot_titles=('Time', 'Speedup'))\n",
    "                        \n",
    "    fig.add_trace(go.Scatter(x=jobs,y=times),row=1,col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=jobs,y=efi_jobs, line=dict(dash='dash')),row=1,col=2)\n",
    "    fig.add_trace(go.Scatter(x=jobs,y=efi_ts), row=1, col=2)\n",
    "    \n",
    "    fig.update_xaxes(type='linear' ,row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(showlegend=False)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def usage_bp(csvs): # _minio, csvs_cern, csvs_cpu):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    #TODO: Add for experiment type\n",
    "    \n",
    "    # Select Required Data\n",
    "    key = '96' # Select Job with 96 mappers as default.\n",
    "    tmp = csvs[key]\n",
    "    tmp = tmp[tmp['function'] == 'mapper']\n",
    "    cpu_use = []\n",
    "    mem_use = []\n",
    "    # For each mapper get the mean of the usage, this will be a data point for the bp.\n",
    "    for elem in pd.unique(tmp['id']):\n",
    "        tmp2 = tmp[tmp['id'] == elem]\n",
    "        cpu_use.append(tmp2['cpu_percent'].mean())\n",
    "        mem_use.append(tmp2['mem_percent'].mean())\n",
    "    \n",
    "    # Generate Plots\n",
    "    fig = make_subplots(rows=2, cols=2, \n",
    "                       subplot_titles=('CERN Data', 'Minio Data', 'CPU'))\n",
    "    \n",
    "    fig.add_trace(go.Box(y=cpu_use, name='CPU Usage'), col=1,row=1)\n",
    "    fig.add_trace(go.Box(y=mem_use, name='Mem Usage'), col=1,row=1)\n",
    "    \n",
    "    fig.add_trace(go.Box(y=cpu_use, name='CPU Usage'), col=2,row=1)\n",
    "    fig.add_trace(go.Box(y=mem_use, name='Mem Usage'), col=2,row=1)\n",
    "    \n",
    "    fig.add_trace(go.Box(y=cpu_use, name='CPU Usage'), col=1,row=2)\n",
    "    fig.add_trace(go.Box(y=mem_use, name='Mem Usage'), col=1,row=2)\n",
    "    \n",
    "    fig.update_layout(showlegend=False)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def usage_timeline(csvs):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    #TODO: Add for experiment\n",
    "    key = '96'\n",
    "    tmp = csvs[key]\n",
    "    tmp = tmp[tmp['function'] == 'mapper']\n",
    "\n",
    "    mapper_data = tmp[tmp['id'] == '95_95']\n",
    "\n",
    "    fig = make_subplots(rows=3, cols=2,\n",
    "                         subplot_titles=['CERN CPU Usage','CERN Mem Usage',\n",
    "                                        'MINIO CPU Usage','MINIO Mem Usage',\n",
    "                                        'CPU CPU Usage','CPU Mem Usage'],\n",
    "                         x_title= 'Time (s)',\n",
    "                         y_title='Usage %')\n",
    "    # CERN\n",
    "    fig.add_trace(go.Scatter(x=mapper_data['time'],\n",
    "                             y=mapper_data['cpu_percent']), \n",
    "                  row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=mapper_data['time'],\n",
    "                             y=mapper_data['mem_percent']), \n",
    "                  row=1, col=2)\n",
    "    \n",
    "    # MINIO\n",
    "    fig.add_trace(go.Scatter(x=mapper_data['time'],\n",
    "                             y=mapper_data['cpu_percent']), \n",
    "                  row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=mapper_data['time'],\n",
    "                             y=mapper_data['mem_percent']), \n",
    "                  row=2, col=2)\n",
    "    \n",
    "    # CPU\n",
    "    fig.add_trace(go.Scatter(x=mapper_data['time'],\n",
    "                             y=mapper_data['cpu_percent']), \n",
    "                  row=3, col=1)\n",
    "    fig.add_trace(go.Scatter(x=mapper_data['time'],\n",
    "                             y=mapper_data['mem_percent']), \n",
    "                  row=3, col=2)\n",
    "    \n",
    "    fig.update_layout(showlegend=False)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e601c4c4",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f1b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minio Data Load\n",
    "csvs_minio_usage = {}\n",
    "csvs_minio_process = {}\n",
    "csv_files = sorted(glob.glob(f'MinioData/*.csv'), key=lambda x: int(x.split('/')[1].split('_')[0]))\n",
    "\n",
    "for file_name in csv_files:\n",
    "    key = file_name.split('_')[0].split('/')[1]\n",
    "    \n",
    "    if file_name.endswith('usage.csv'):\n",
    "        csvs_minio_usage[key] = pd.read_csv(file_name, delimiter='|')\n",
    "    elif file_name.endswith('process.csv'):\n",
    "        csvs_minio_process[key] = pd.read_csv(file_name, delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CERN Data Load\n",
    "csvs_cern_usage = {}\n",
    "csvs_cern_process = {}\n",
    "csv_files = sorted(glob.glob(f'CERNData/*.csv'), key=lambda x: int(x.split('/')[1].split('_')[0]))\n",
    "\n",
    "for file_name in csv_files:\n",
    "    key = file_name.split('_')[0].split('/')[1]\n",
    "    \n",
    "    if file_name.endswith('usage.csv'):\n",
    "        csvs_cern_usage[key] = pd.read_csv(file_name, delimiter='|')\n",
    "    elif file_name.endswith('process.csv'):\n",
    "        csvs_cern_process[key] = pd.read_csv(file_name, delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU Data Load\n",
    "csvs_cpu_usage = {}\n",
    "csvs_cpu_process = {}\n",
    "csv_files = sorted(glob.glob(f'SimulatedData/*.csv'), key=lambda x: int(x.split('/')[1].split('_')[0]))\n",
    "\n",
    "for file_name in csv_files:\n",
    "    key = file_name.split('_')[0].split('/')[1]\n",
    "    \n",
    "    if file_name.endswith('usage.csv'):\n",
    "        csvs_cpu_usage[key] = pd.read_csv(file_name, delimiter='|')\n",
    "    elif file_name.endswith('process.csv'):\n",
    "        csvs_cpu_process[key] = pd.read_csv(file_name, delimiter='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c9ff6",
   "metadata": {},
   "source": [
    "## Plot Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740fff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "eficiency(csvs_minio_usage)\n",
    "usage_bp(csvs_minio_usage)\n",
    "usage_timeline(csvs_minio_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b54db",
   "metadata": {},
   "source": [
    "## Process Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68342f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('264285c4-098b-433f-90ae-e6c91eb68716_process.csv' , delimiter='|')\n",
    "df2 = df2[df2['function'] == 'mapper']\n",
    "cols = ['function', 'id', 'phase', 'node'] + [col_name for col_name in df2 if col_name.startswith('ctx_') ]\n",
    "df_ctx = df2[cols]\n",
    "df_ctx = df_ctx[df_ctx['phase'] == 'end']\n",
    "df_ctx.sort_values('ctx_involuntary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551468b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#cpu1_1 = pd.read_csv('', delimiter='')\n",
    "cpu1_2 = pd.read_csv('cpu_bound_1/28eb5163-faf9-485c-85e7-ed594cf7994f_usage.csv', delimiter='|')\n",
    "cpu1_4 = pd.read_csv('cpu_bound_1/deea2089-6ee4-4a7b-a8a0-1f25b0083f8c_usage.csv', delimiter='|')\n",
    "cpu1_8 = pd.read_csv('cpu_bound_1/c3ce453f-9869-4482-9a87-abc7ad1f9bc6_usage.csv', delimiter='|')\n",
    "cpu1_16= pd.read_csv('cpu_bound_1/21bcd8bb-7d0b-4f32-b998-a71ddad2318b_usage.csv', delimiter='|')\n",
    "\n",
    "csvs = { 'cpu1-16': cpu1_16, 'cpu1-8': cpu1_8, 'cpu1-4': cpu1_4, 'cpu1-2': cpu1_2}\n",
    "plot_mapper_times(csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aeaf5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cpu0_98_2 = pd.read_csv('cpu_bound_0.98/2_usage.csv', delimiter='|')\n",
    "cpu0_98_4 = pd.read_csv('cpu_bound_0.98/4_usage.csv', delimiter='|')\n",
    "cpu0_98_8 = pd.read_csv('cpu_bound_0.98/8_usage.csv', delimiter='|')\n",
    "cpu0_98_16= pd.read_csv('cpu_bound_0.98/16_usage.csv', delimiter='|')\n",
    "\n",
    "csvs = { 'cpu0.98-16': cpu0_98_16, 'cpu0.98-8': cpu0_98_8, 'cpu0.98-4': cpu0_98_4, 'cpu0.98-2': cpu0_98_2}\n",
    "plot_mapper_times(csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for item in csvs:\n",
    "    tmp = csvs[item]\n",
    "    tmp = tmp[tmp['function'] ==  'reducer']\n",
    "\n",
    "    tmp_time = 0\n",
    "    name = f'size_{item.split(\"_\")[0]}'\n",
    "    times[name] = [[], []]\n",
    "    for elem in pd.unique(tmp['id']):\n",
    "        tmp2 = tmp[tmp['id'] == elem]\n",
    "        print(tmp2)\n",
    "        reducer_time = float(tmp2['time'].iloc[[-1]].values[0]) - float(tmp2['time'].iloc[[0]].values[0]) \n",
    "        print('\\n\\n')\n",
    "        tmp_time += reducer_time\n",
    "        times[name][0].append(tmp2['time'].iloc[[-1]].values[0] - tmp2['time'].iloc[[0]].values[0]) \n",
    "        times[name][1].append(tmp2['node'].iloc[[-1]].values[0])\n",
    "        #times[name][0].sort()\n",
    "\n",
    "    #print('Reduer count: ')    \n",
    "    #print(f'Job: {name}. Average Time: {sum(tmp_time)/len(tmp_time)} - Median: {statistics.median(tmp_time)}')\n",
    "    print(tmp_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44394af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu1_16 = pd.read_csv('test1/16_usage.csv', delimiter='|')\n",
    "\n",
    "csvs = { 'cpu16': cpu1_16}\n",
    "plot_mapper_times(csvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd57a7",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'SimulatedData'\n",
    "csvs = [f'{prefix}/{file_name}' for file_name in os.listdir('SimulatedData/') if file_name.endswith('usage.csv')]\n",
    "times = {}\n",
    "print(csvs)\n",
    "for item in csvs:\n",
    "    tmp = pd.read_csv(item, delimiter='|')\n",
    "    tmp = tmp[tmp['function'] ==  'mapper']\n",
    "\n",
    "    tmp_time = []\n",
    "    name = f'size_{item.split(\"/\")[1].split(\"_\")[0]}'\n",
    "    \n",
    "    times[name] = [[], []]\n",
    "    for elem in pd.unique(tmp['id']):\n",
    "        tmp2 = tmp[tmp['id'] == elem]\n",
    "        mapper_time = float(tmp2['time'].iloc[[-1]].values[0]) - float(tmp2['time'].iloc[[0]].values[0]) \n",
    "        tmp_time.append(mapper_time)\n",
    "        times[name][0].append(tmp2['time'].iloc[[-1]].values[0] - tmp2['time'].iloc[[0]].values[0]) \n",
    "        times[name][1].append(tmp2['node'].iloc[[-1]].values[0])\n",
    "        #times[name][0].sort()\n",
    "\n",
    "    print(f'Job: {name}. Average Time: {sum(tmp_time)/len(tmp_time)} - Median: {statistics.median(tmp_time)}')\n",
    "\n",
    "# Box Plot\n",
    "#bp = go.Figure()\n",
    "nodes = ['wn1.localdomain', 'wn2.localdomain', 'wn3.localdomain',\n",
    "         'wn4.localdomain', 'wn5.localdomain', 'wn6.localdomain']\n",
    "colors = ['red', 'green', 'blue', 'black', 'orange', 'purple']\n",
    "\n",
    "\n",
    "for k in times:\n",
    "bp = go.Figure()\n",
    "    bp.add_trace(go.Box(y=times[k][0], \n",
    "                        name=f'Job {k}', \n",
    "                        boxpoints='all', \n",
    "                        text=times[k][1]))\n",
    "                        #marker=dict(color=colors\n",
    "                        #            ),\n",
    "                        #mode='markers'))\n",
    "\n",
    "    bp.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
